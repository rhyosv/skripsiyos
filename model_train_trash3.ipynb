{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xlZOdHLhoaKR",
        "outputId": "f5dd0a65-0b33-4b7a-98ef-f6932524b54d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fAenK5khorHW",
        "outputId": "ad165704-9085-472d-8254-fcc7f01337ae"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/content/drive/MyDrive/Project/trash4\n"
          ]
        }
      ],
      "source": [
        "%cd \"/content/drive/MyDrive/Project/trash4\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Y1d-QNDouWl"
      },
      "outputs": [],
      "source": [
        "# !unzip recycling\\ waste.zip"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3sxGFMPIowEl"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WDrpOLW8oyZ1",
        "outputId": "ae192d21-0664-4271-9adf-26e517a5c24d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 8369 images belonging to 9 classes.\n"
          ]
        }
      ],
      "source": [
        "# let's prepare the data and generate the data\n",
        "\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "gen_train = ImageDataGenerator(rescale = 1/255, shear_range = 0.2, zoom_range = 0.2, \n",
        "                               brightness_range = (0.1, 0.5), horizontal_flip=True)\n",
        "\n",
        "train_data = gen_train.flow_from_directory(\"/content/drive/MyDrive/Project/trash4/Data\",\n",
        "                                           target_size = (224, 224), batch_size = 32, class_mode=\"categorical\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cbco8M4Jo1L2",
        "outputId": "e15c1bfd-a4e3-4395-96fb-f7681a10f17e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/vgg16/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "58892288/58889256 [==============================] - 0s 0us/step\n",
            "58900480/58889256 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# let's create a model\n",
        "# here i'm going to use VGG16 model's parameter to solve this problem\n",
        "\n",
        "from tensorflow.keras.applications.vgg16 import VGG16\n",
        "\n",
        "# here i'm going to take input shape, weights and bias from imagenet and include top False means\n",
        "# i want to add input, flatten and output layer by my self\n",
        "\n",
        "vgg16 = VGG16(input_shape = (224, 224, 3), weights = \"imagenet\", include_top = False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UUYnEGh9o2FN"
      },
      "outputs": [],
      "source": [
        "# now vgg16 weights are already train so i don't want to train that weights again\n",
        "# so let's make trainable = False\n",
        "\n",
        "for layer in vgg16.layers:\n",
        "  layer.trainable = False"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jz6bYHNOo5Y1"
      },
      "outputs": [],
      "source": [
        "# let's add flatten layer or let's connect VGG16 with our own flatten layer\n",
        "\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "x = layers.Flatten()(vgg16.output)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "i2jYVDILo7X9",
        "outputId": "b9209e3e-14f6-4af1-caa4-c73a1f07df12"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"model\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " input_1 (InputLayer)        [(None, 224, 224, 3)]     0         \n",
            "                                                                 \n",
            " block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n",
            "                                                                 \n",
            " block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n",
            "                                                                 \n",
            " block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n",
            "                                                                 \n",
            " block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n",
            "                                                                 \n",
            " block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n",
            "                                                                 \n",
            " block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n",
            "                                                                 \n",
            " block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n",
            "                                                                 \n",
            " block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n",
            "                                                                 \n",
            " block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n",
            "                                                                 \n",
            " block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n",
            "                                                                 \n",
            " block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n",
            "                                                                 \n",
            " block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n",
            "                                                                 \n",
            " block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n",
            "                                                                 \n",
            " block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n",
            "                                                                 \n",
            " flatten (Flatten)           (None, 25088)             0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 9)                 225801    \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 14,940,489\n",
            "Trainable params: 225,801\n",
            "Non-trainable params: 14,714,688\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# now let's add output layers or prediction layer\n",
        "\n",
        "prediction = layers.Dense(units = 9, activation=\"softmax\")(x)\n",
        "\n",
        "# creating a model object\n",
        "\n",
        "model = tf.keras.models.Model(inputs = vgg16.input, outputs=prediction)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "background_save": true,
          "base_uri": "https://localhost:8080/"
        },
        "id": "uZ4CXzbDo9--",
        "outputId": "b23daac9-f6e6-497a-de86-e1f264f36c45"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:5: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  \"\"\"\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/28\n",
            "262/262 [==============================] - 4271s 16s/step - loss: 1.9236 - accuracy: 0.3365\n",
            "Epoch 2/28\n",
            "262/262 [==============================] - 4173s 16s/step - loss: 1.6318 - accuracy: 0.4400\n",
            "Epoch 3/28\n",
            "262/262 [==============================] - 4136s 16s/step - loss: 1.4488 - accuracy: 0.5029\n",
            "Epoch 4/28\n"
          ]
        }
      ],
      "source": [
        "# now let's compile the model\n",
        "\n",
        "model.compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics =[\"accuracy\"])\n",
        "\n",
        "result = model.fit_generator(train_data, epochs = 28, steps_per_epoch=len(train_data))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_79N83QYpBoW"
      },
      "outputs": [],
      "source": [
        "from tensorflow.keras.preprocessing import image\n",
        "output_class = [\"batteries\", \"clothes\", \"e-waste\", \"glass\", \"light blubs\", \"metal\", \"organic\", \"paper\", \"plastic\"]\n",
        "def waste_prediction(new_image):\n",
        "  test_image = image.load_img(new_image, target_size = (224,224))\n",
        "  plt.axis(\"off\")\n",
        "  plt.imshow(test_image)\n",
        "  plt.show()\n",
        " \n",
        "  test_image = image.img_to_array(test_image) / 255\n",
        "  test_image = np.expand_dims(test_image, axis=0)\n",
        "\n",
        "  predicted_array = model.predict(test_image)\n",
        "  predicted_value = output_class[np.argmax(predicted_array)]\n",
        "  predicted_accuracy = round(np.max(predicted_array) * 100, 2)\n",
        "\n",
        "  print(\"Limbah yang anda masukan adalah \", predicted_value, \" dengan \", predicted_accuracy, \" % accuracy\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3DTc9EM1pER9"
      },
      "outputs": [],
      "source": [
        "waste_prediction(\"toy.jpg\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MnwYzCWopHc1"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Accuracy\")\n",
        "plt.plot(result.history[\"accuracy\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "73nAd0w8pJJl"
      },
      "outputs": [],
      "source": [
        "plt.title(\"Loss\")\n",
        "plt.plot(result.history[\"loss\"])\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VXpjWS8-pLFl"
      },
      "outputs": [],
      "source": [
        "model.save(\"classifyWaste.h5\")"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "model_train_trash3.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}